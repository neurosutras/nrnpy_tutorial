{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "num_hidden_layers = 0\n",
    "input_dim = 10\n",
    "hidden_dim = 10\n",
    "output_dim = input_dim\n",
    "sigma = 0.75  # 2\n",
    "wrap = True\n",
    "input_peak_rate = 1.\n",
    "num_blocks = 10  # each block contains all input patterns\n",
    "\n",
    "hidden_layer_target_density = 0.2\n",
    "inhib_gate_shape = 4.\n",
    "\n",
    "activation_f = lambda x: x\n",
    "\n",
    "learning_rate = 0.25\n",
    "dep_ratio = 1.\n",
    "dep_th = 0.01\n",
    "dep_width = 0.01\n",
    "update_FB_weights = True\n",
    "set_output_activities = True\n",
    "\n",
    "this_random = np.random.RandomState()\n",
    "this_random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pattern_matrix = np.empty([input_dim,input_dim])\n",
    "target_output_matrix = np.zeros([input_dim,input_dim])\n",
    "\n",
    "input_indexes = np.arange(0, input_dim)\n",
    "center_index = (input_dim-1)//2\n",
    "field = input_peak_rate * np.exp(-((input_indexes-center_index)/sigma)**2.)\n",
    "\n",
    "for i in input_indexes:\n",
    "    if wrap:\n",
    "        input_pattern_matrix[i,:] = np.roll(field, i-center_index)\n",
    "    else:\n",
    "        input_pattern_matrix[i,:] = input_peak_rate * np.exp(-((input_indexes-i)/sigma)**2.)\n",
    "\n",
    "target_output_matrix = np.copy(input_pattern_matrix)\n",
    "\n",
    "num_input_patterns = input_pattern_matrix.shape[-1]\n",
    "input_layer_density = np.mean(np.mean(input_pattern_matrix, axis=0))\n",
    "output_layer_density = np.mean(np.mean(target_output_matrix, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10,3))\n",
    "axes[0].plot(input_indexes, field)\n",
    "axes[0].set_ylabel('Input unit activity')\n",
    "axes[0].set_xlabel('Latent dimension')\n",
    "\n",
    "cbar = axes[1].imshow(input_pattern_matrix)\n",
    "fig.colorbar(cbar, ax=axes[1])\n",
    "axes[1].set_xlabel('Input pattern')\n",
    "axes[1].set_ylabel('Input unit')\n",
    "axes[1].set_title('Input activities')\n",
    "\n",
    "cbar = axes[2].imshow(target_output_matrix)\n",
    "fig.colorbar(cbar, ax=axes[2])\n",
    "axes[2].set_xlabel('Input pattern')\n",
    "axes[2].set_ylabel('Output unit')\n",
    "axes[2].set_title('Target output activities')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_weight_scale = 2.\n",
    "initial_weight_scale = max_weight_scale / 2.\n",
    "\n",
    "initial_FF_weight_scale_dict = {}\n",
    "initial_FB_weight_scale_dict = {}\n",
    "max_FF_weight_dict = {}\n",
    "max_FB_weight_dict = {}\n",
    "num_layers = num_hidden_layers + 2\n",
    "layer_dims = [input_dim] + num_hidden_layers * [hidden_dim] + [output_dim]\n",
    "layer_densities = [input_layer_density] + num_hidden_layers * [hidden_layer_target_density] + [output_layer_density]\n",
    "\n",
    "initial_FF_weight_matrix_dict = {}\n",
    "initial_FB_weight_matrix_dict = {}\n",
    "\n",
    "for layer in range(1, num_layers):\n",
    "    prev_layer_dim = layer_dims[layer-1]\n",
    "    curr_layer_dim = layer_dims[layer]\n",
    "    prev_layer_density = layer_densities[layer-1]\n",
    "    curr_layer_density = layer_densities[layer]\n",
    "    this_initial_weight_scale = initial_weight_scale / prev_layer_dim / prev_layer_density * curr_layer_density\n",
    "    initial_FF_weight_scale_dict[layer] = this_initial_weight_scale\n",
    "    this_max_weight = max_weight_scale / prev_layer_dim / prev_layer_density\n",
    "    max_FF_weight_dict[layer] = this_max_weight\n",
    "    initial_FF_weight_matrix_dict[layer] = this_random.uniform(0., this_initial_weight_scale, [curr_layer_dim, prev_layer_dim])\n",
    "    \n",
    "for layer in range(1, num_layers - 1):\n",
    "    next_layer_dim = layer_dims[layer+1]\n",
    "    curr_layer_dim = layer_dims[layer]\n",
    "    next_layer_density = layer_densities[layer+1]\n",
    "    curr_layer_density = layer_densities[layer]\n",
    "    this_initial_weight_scale = initial_weight_scale / next_layer_dim / next_layer_density * curr_layer_density\n",
    "    initial_FB_weight_scale_dict[layer] = this_initial_weight_scale\n",
    "    this_max_weight = max_weight_scale / next_layer_dim / next_layer_density\n",
    "    max_FB_weight_dict[layer] = this_max_weight\n",
    "    initial_FB_weight_matrix_dict[layer] = this_random.uniform(0., this_initial_weight_scale, [curr_layer_dim, next_layer_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layer_densities)\n",
    "print(max_FF_weight_dict)\n",
    "print(max_FB_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_activities(input_pattern_matrix, FF_weight_matrix_dict, FB_weight_matrix_dict, activation_f, target_output_matrix=None, set_output_activities=False):\n",
    "    FF_input_activities_dict = {}\n",
    "    FB_input_activities_dict = {}\n",
    "    layer_output_activities_dict = {}\n",
    "    layer_output_activities_dict[0] = np.copy(input_pattern_matrix)\n",
    "    prev_layer_activities = input_pattern_matrix\n",
    "    sorted_layers = sorted(list(FF_weight_matrix_dict.keys()))\n",
    "    output_layer = max(sorted_layers)\n",
    "    for layer in sorted_layers:\n",
    "        curr_layer_input_activities = FF_weight_matrix_dict[layer].dot(prev_layer_activities)\n",
    "        FF_input_activities_dict[layer] = np.copy(curr_layer_input_activities)\n",
    "        if layer == output_layer and set_output_activities:\n",
    "            if target_output_matrix is None:\n",
    "                raise RuntimeError('get_layer_activities: cannot set_output_activities without target_output_matrix')\n",
    "            curr_layer_output_activities = target_output_matrix\n",
    "        else:\n",
    "            curr_layer_output_activities = activation_f(curr_layer_input_activities)\n",
    "        layer_output_activities_dict[layer] = np.copy(curr_layer_output_activities)\n",
    "        prev_layer_activities = curr_layer_output_activities\n",
    "    for layer in sorted(list(FB_weight_matrix_dict), reverse=True):\n",
    "        curr_layer_input_activities = FB_weight_matrix_dict[layer].dot(prev_layer_activities)\n",
    "        FB_input_activities_dict[layer] = np.copy(curr_layer_input_activities)\n",
    "        prev_layer_activities = layer_output_activities_dict[layer]\n",
    "    return FF_input_activities_dict, FB_input_activities_dict, layer_output_activities_dict\n",
    "\n",
    "\n",
    "def plot_network_state_summary(FF_weight_matrix_dict, FB_weight_matrix_dict, FF_input_activities_dict, FB_input_activities_dict, layer_output_activities_dict):    \n",
    "\n",
    "    fig, axes = plt.subplots(5, len(FF_weight_matrix_dict) + 1, figsize=(int(len(FF_weight_matrix_dict) + 1) * 3.5, 2.5 * 5))\n",
    "    for layer in sorted(list(layer_output_activities_dict.keys())):\n",
    "        if layer in FF_weight_matrix_dict:\n",
    "            cbar = axes[0][layer].imshow(FF_weight_matrix_dict[layer])\n",
    "            fig.colorbar(cbar, ax=axes[0][layer])\n",
    "            axes[0][layer].set_title('FF weights: layer %i' % layer)\n",
    "            axes[0][layer].set_ylabel('Layer %i units' % layer)\n",
    "            axes[0][layer].set_xlabel('Layer %i units' % (layer - 1))\n",
    "\n",
    "            cbar = axes[1][layer].imshow(FF_input_activities_dict[layer])\n",
    "            fig.colorbar(cbar, ax=axes[1][layer])\n",
    "            axes[1][layer].set_title('FF input activities: layer %i' % layer)\n",
    "            axes[1][layer].set_ylabel('Layer %i units' % layer)\n",
    "            axes[1][layer].set_xlabel('Input patterns')\n",
    "        \n",
    "        cbar = axes[2][layer].imshow(layer_output_activities_dict[layer])\n",
    "        fig.colorbar(cbar, ax=axes[2][layer])\n",
    "        if layer == 0:\n",
    "            axes[2][layer].set_title('Input layer activities')\n",
    "        else:\n",
    "            axes[2][layer].set_title('Output activities: layer %i' % layer)\n",
    "        axes[2][layer].set_ylabel('Layer %i units' % layer)\n",
    "        axes[2][layer].set_xlabel('Input patterns')\n",
    "        \n",
    "        if layer in FB_weight_matrix_dict:\n",
    "            cbar = axes[3][layer].imshow(FB_weight_matrix_dict[layer])\n",
    "            fig.colorbar(cbar, ax=axes[3][layer])\n",
    "            axes[3][layer].set_title('FB weights: layer %i' % layer)\n",
    "            axes[3][layer].set_ylabel('Layer %i units' % layer)\n",
    "            axes[3][layer].set_xlabel('Layer %i units' % (layer + 1))\n",
    "\n",
    "            cbar = axes[4][layer].imshow(FB_input_activities_dict[layer])\n",
    "            fig.colorbar(cbar, ax=axes[4][layer])\n",
    "            axes[4][layer].set_title('FB input activities: layer %i' % layer)\n",
    "            axes[4][layer].set_ylabel('Layer %i units' % layer)\n",
    "            axes[4][layer].set_xlabel('Input patterns')\n",
    "        axes[3][-1].axis('off')\n",
    "        axes[4][-1].axis('off')\n",
    "    for i in range(len(axes)):\n",
    "        if i != 2:\n",
    "            axes[i, 0].axis('off')\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.8)\n",
    "    fig.show()\n",
    "    print('Activity densities:')\n",
    "    for layer in layer_output_activities_dict:\n",
    "        print('layer %i: %.2f' % (layer, np.mean(np.mean(layer_output_activities_dict[layer], axis=0))))\n",
    "        \n",
    "\n",
    "\n",
    "def scaled_single_sigmoid(th, peak, x=None, ylim=None):\n",
    "    \"\"\"\n",
    "    Transform a sigmoid to intersect x and y range limits.\n",
    "    :param th: float\n",
    "    :param peak: float\n",
    "    :param x: array\n",
    "    :param ylim: pair of float\n",
    "    :return: callable\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        x = (0., 1.)\n",
    "    if ylim is None:\n",
    "        ylim = (0., 1.)\n",
    "    if th < x[0] or th > x[-1]:\n",
    "        raise ValueError('scaled_single_sigmoid: th: %.2E is out of range for xlim: [%.2E, %.2E]' % (th, x[0], x[-1]))\n",
    "    if peak == th:\n",
    "        raise ValueError('scaled_single_sigmoid: peak and th: %.2E cannot be equal' % th)\n",
    "    slope = 2. / (peak - th)\n",
    "    y = lambda x: 1. / (1. + np.exp(-slope * (x - th)))\n",
    "    start_val = y(x[0])\n",
    "    end_val = y(x[-1])\n",
    "    amp = end_val - start_val\n",
    "    target_amp = ylim[1] - ylim[0]\n",
    "    return lambda xi: (target_amp / amp) * (1. / (1. + np.exp(-slope * (xi - th))) - start_val) + ylim[0]\n",
    "\n",
    "\n",
    "def get_BTSP_delta_w(learning_rate, dep_ratio, dep_th, dep_width):\n",
    "    f_dep = scaled_single_sigmoid(dep_th, dep_th + dep_width)\n",
    "    return np.vectorize(lambda pre, w, mod, w_max: learning_rate * ((w_max - w) * pre * mod - w * dep_ratio * f_dep(pre * mod)), excluded=['mod', 'w_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "BTSP_delta_w = get_BTSP_delta_w(learning_rate, dep_ratio, dep_th, dep_width)\n",
    "pre = np.linspace(0., input_peak_rate, 100)\n",
    "w0 = np.linspace(0., max_weight_scale, 100)\n",
    "pre_mesh, w0_mesh = np.meshgrid(pre, w0)\n",
    "plt.figure()\n",
    "plt.pcolormesh(pre_mesh, w0_mesh, BTSP_delta_w(pre_mesh, w0_mesh, 1., max_weight_scale), cmap='RdBu_r', shading='nearest', vmin=-max_weight_scale * learning_rate, \n",
    "               vmax=max_weight_scale * learning_rate)\n",
    "plt.xlabel('Pre activity')\n",
    "plt.ylabel('Initial weight')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Delta weight', rotation=-90.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inhib_gate(x, target_density, shape):\n",
    "    y = lambda x: np.exp(shape * ((x / target_density) - 1.))\n",
    "    return (y(x) - y(0.)) / (1. - y(0.))\n",
    "target_density = 0.2\n",
    "plt.figure()\n",
    "test = np.linspace(0., target_density, 100)\n",
    "plt.plot(test, inhib_gate(test, target_density, inhib_gate_shape))\n",
    "plt.xlabel('Mean layer activity')\n",
    "plt.ylabel('Inhibition of plasticity threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_mod_activities(FF_input_activities_dict, FB_input_activities_dict, layer_output_activities_dict, target_mod, layer_densities):\n",
    "    # print('Hidden layer update not yet implemented')\n",
    "    layer_mod_activities_dict = {}\n",
    "    num_layers = len(layer_densities)\n",
    "    for layer in range(1, num_layers):\n",
    "        if layer == num_layers - 1:\n",
    "            layer_mod_activities_dict[layer] = np.copy(target_mod)\n",
    "        else:\n",
    "            inhib = inhib_gate(np.mean(layer_output_activities_dict[layer]), layer_densities[layer], inhib_gate_shape)\n",
    "            FF_gate = np.heaviside(FF_input_activities_dict[layer] - inhib, 1.)\n",
    "            FB_gate = np.heaviside(FB_input_activities_dict[layer] - inhib, 1.)\n",
    "            layer_mod_activities_dict[layer] = np.multiply(FF_gate, FB_gate)\n",
    "    return layer_mod_activities_dict\n",
    "\n",
    "\n",
    "def get_BTSP_delta_weights(layer_output_activities_dict, layer_mod_activities_dict, FF_weight_matrix_dict, FB_weight_matrix_dict, max_FF_weight_dict, max_FB_weight_dict, \n",
    "                           update_FB_weights=False):\n",
    "    delta_FF_weight_matrix_dict = {}\n",
    "    delta_FB_weight_matrix_dict = {}\n",
    "    for layer in FF_weight_matrix_dict:\n",
    "        pre = layer_output_activities_dict[layer - 1]\n",
    "        mod = layer_mod_activities_dict[layer]\n",
    "        max_weight = max_FF_weight_dict[layer]\n",
    "        delta_FF_weight_matrix = np.empty_like(FF_weight_matrix_dict[layer])\n",
    "        for i in range(len(mod)):\n",
    "            delta_FF_weight_matrix[i] = BTSP_delta_w(pre, FF_weight_matrix_dict[layer][i], mod[i], max_weight)\n",
    "        delta_FF_weight_matrix_dict[layer] = np.copy(delta_FF_weight_matrix)\n",
    "    for layer in FB_weight_matrix_dict:\n",
    "        if update_FB_weights:\n",
    "            pre = layer_output_activities_dict[layer + 1]\n",
    "            mod = layer_mod_activities_dict[layer]\n",
    "            max_weight = max_FB_weight_dict[layer]\n",
    "            delta_FB_weight_matrix = np.empty_like(FB_weight_matrix_dict[layer])\n",
    "            for i in range(len(mod)):\n",
    "                delta_FB_weight_matrix[i] = BTSP_delta_w(pre, FB_weight_matrix_dict[layer][i], mod[i], max_weight)\n",
    "            delta_FB_weight_matrix_dict[layer] = np.copy(delta_FB_weight_matrix)\n",
    "        else:\n",
    "            delta_FB_weight_matrix_dict[layer] = np.zeros_like(FB_weight_matrix_dict[layer])\n",
    "    return delta_FF_weight_matrix_dict, delta_FB_weight_matrix_dict\n",
    "    \n",
    "\n",
    "def train_BTSP(input_pattern_matrix, target_output_matrix, initial_FF_weight_matrix_dict, initial_FB_weight_matrix_dict, num_blocks, layer_densities, activation_f, \n",
    "               max_FF_weight_dict, max_FB_weight_dict, update_FB_weights=False, set_output_activities=False):\n",
    "    \n",
    "    FF_weight_matrix_dict = deepcopy(initial_FF_weight_matrix_dict)\n",
    "    FB_weight_matrix_dict = deepcopy(initial_FB_weight_matrix_dict)\n",
    "    FF_weight_matrix_dict_history = []\n",
    "    FB_weight_matrix_dict_history = []\n",
    "    delta_FF_weight_matrix_dict_history = []\n",
    "    delta_FB_weight_matrix_dict_history = []\n",
    "    input_pattern_index_history = []\n",
    "    layer_output_activities_dict_history = []\n",
    "    layer_mod_activities_dict_history = []\n",
    "    \n",
    "    num_layers = len(layer_densities)\n",
    "    for block in range(num_blocks):\n",
    "        input_pattern_indexes = np.arange(input_pattern_matrix.shape[-1])\n",
    "        this_random.shuffle(input_pattern_indexes)\n",
    "        for input_pattern_index in input_pattern_indexes:\n",
    "            input_pattern_index_history.append(input_pattern_index)\n",
    "            input_pattern = input_pattern_matrix[:, input_pattern_index]\n",
    "            target_output = target_output_matrix[:, input_pattern_index]\n",
    "            target_mod = np.zeros_like(target_output)\n",
    "            target_mod[np.argmax(target_output)] = 1.\n",
    "            FF_input_activities_dict, FB_input_activities_dict, layer_output_activities_dict = \\\n",
    "                get_layer_activities(input_pattern, FF_weight_matrix_dict, FB_weight_matrix_dict, activation_f, target_output, set_output_activities)\n",
    "            layer_mod_activities_dict = get_layer_mod_activities(FF_input_activities_dict, FB_input_activities_dict, layer_output_activities_dict, target_mod, layer_densities)\n",
    "            delta_FF_weight_matrix_dict, delta_FB_weight_matrix_dict = \\\n",
    "                get_BTSP_delta_weights(layer_output_activities_dict, layer_mod_activities_dict, FF_weight_matrix_dict, FB_weight_matrix_dict, max_FF_weight_dict, max_FB_weight_dict, \n",
    "                                       update_FB_weights)\n",
    "            delta_FF_weight_matrix_dict_history.append(deepcopy(delta_FF_weight_matrix_dict))\n",
    "            delta_FB_weight_matrix_dict_history.append(deepcopy(delta_FB_weight_matrix_dict))\n",
    "            layer_output_activities_dict_history.append(deepcopy(layer_output_activities_dict))\n",
    "            layer_mod_activities_dict_history.append(deepcopy(layer_mod_activities_dict))\n",
    "            for layer in FF_weight_matrix_dict:\n",
    "                FF_weight_matrix_dict[layer] += delta_FF_weight_matrix_dict[layer]\n",
    "            if update_FB_weights:\n",
    "                for layer in FB_weight_matrix_dict:\n",
    "                    FB_weight_matrix_dict[layer] += delta_FB_weight_matrix_dict[layer]\n",
    "            FF_weight_matrix_dict_history.append(deepcopy(FF_weight_matrix_dict))\n",
    "            FB_weight_matrix_dict_history.append(deepcopy(FB_weight_matrix_dict))\n",
    "    return FF_weight_matrix_dict_history, FB_weight_matrix_dict_history, delta_FF_weight_matrix_dict_history, delta_FB_weight_matrix_dict_history, input_pattern_index_history, \\\n",
    "        layer_output_activities_dict_history, layer_mod_activities_dict_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_weight_matrix_dict_history, FB_weight_matrix_dict_history, delta_FF_weight_matrix_dict_history, delta_FB_weight_matrix_dict_history, input_pattern_index_history, \\\n",
    "    layer_output_activities_dict_history, layer_mod_activities_dict_history = \\\n",
    "    train_BTSP(input_pattern_matrix, target_output_matrix, initial_FF_weight_matrix_dict, initial_FB_weight_matrix_dict, num_blocks, layer_densities, activation_f, max_FF_weight_dict, \n",
    "               max_FB_weight_dict, update_FB_weights=update_FB_weights, set_output_activities=set_output_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_input_activities_dict, FB_input_activities_dict, layer_output_activities_dict = \\\n",
    "    get_layer_activities(input_pattern_matrix, initial_FF_weight_matrix_dict, initial_FB_weight_matrix_dict, activation_f)\n",
    "plot_network_state_summary(initial_FF_weight_matrix_dict, initial_FB_weight_matrix_dict, FF_input_activities_dict, FB_input_activities_dict, layer_output_activities_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indexes = []\n",
    "start_index = 0\n",
    "for i in range(num_blocks):\n",
    "    sorted_indexes.extend(np.add(start_index, np.argsort(input_pattern_index_history[start_index:start_index+input_dim])))\n",
    "    start_index += input_dim\n",
    "sorted_indexes = np.array(sorted_indexes)\n",
    "\n",
    "fig, axes = plt.subplots(num_layers, figsize=(num_blocks * 1.5, num_layers * 2.))\n",
    "cbar = axes[0].imshow(np.column_stack([input_pattern_matrix[:,input_pattern_index_history[i]] for i in sorted_indexes]), aspect='auto')\n",
    "fig.colorbar(cbar, ax=axes[0])\n",
    "axes[0].set_ylabel('Layer 0 units')\n",
    "axes[0].set_xlabel('Sorted input patterns')\n",
    "axes[0].set_title('Input layer activities')\n",
    "for layer in range(1, num_layers):\n",
    "    cbar = axes[layer].imshow(np.column_stack([layer_mod_activities_dict_history[i][layer] for i in sorted_indexes]), aspect='auto')\n",
    "    fig.colorbar(cbar, ax=axes[layer])\n",
    "    axes[layer].set_ylabel('Layer %i units' % layer)\n",
    "    axes[layer].set_xlabel('Sorted input patterns')\n",
    "    axes[layer].set_title('Layer %i modulatory events' % layer)\n",
    "fig.tight_layout()\n",
    "# fig.subplots_adjust(wspace=0.1, hspace=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_input_activities_dict, FB_input_activities_dict, layer_output_activities_dict = \\\n",
    "    get_layer_activities(input_pattern_matrix, FF_weight_matrix_dict_history[-1], FB_weight_matrix_dict_history[-1], activation_f)\n",
    "plot_network_state_summary(FF_weight_matrix_dict_history[-1], FB_weight_matrix_dict_history[-1], FF_input_activities_dict, FB_input_activities_dict, layer_output_activities_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(layer_output_activities_dict[num_layers-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-greene",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
