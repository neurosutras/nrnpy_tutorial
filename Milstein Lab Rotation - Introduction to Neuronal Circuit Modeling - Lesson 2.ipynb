{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Introduction to git, optimization, and spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson goals:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install PyCharm and configure a project with Github integration for this code repository\n",
    "2. git commands: pull, stash, add, commit, merge, push\n",
    "3. Introduction to function optimization with scipy.optimize\n",
    "4. Perform bounded parameter optimization on the input resistance of a NEURON section\n",
    "5. Introduction to NMODL, the language used to specify ion channel mechanisms in NEURON\n",
    "6. Insert \"active\" voltage-dependent \"Hodgkin-Huxley\" ion channels\n",
    "7. Challenge 1: Measure and plot an \"f-I curve\"\n",
    "8. Challenge 2: Simultaneously optimize both somatic input resistance and the slope of the f-I curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install PyCharm and configure a project with Github integration for this code repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.jetbrains.com/pycharm/download/#section=mac\n",
    "\n",
    "### In Pycharm:\n",
    "- Top Menu --> File --> New Project...\n",
    "- Set \"Location\" to directory containing nrnpy_tutorial repository\n",
    "- Set \"Python Interpreter\" to \"Existing Interpreter\" and point to python executable in anaconda bin directory\n",
    "- \"Create\"\n",
    "- \"Create from existing sources\"\n",
    "- Open project in \"New Window\"\n",
    "- Let PyCharm find importable python modules and do some indexing\n",
    "<br><br>\n",
    "- Top Menu --> PyCharm --> Preferences...\n",
    "- Project:nrnpy_tutorial --> Python Interpreter\n",
    "- Click settings gear on top right --> \"Show All\"\n",
    "- Click directory hierarchy icon on bottom \"Show paths for the selected interpreter\"\n",
    "- If not already in the list, make sure to \"Add\" the \"parent directory\" that contains the subdirectory with your cloned git repository\n",
    "- Back in the Preferences panel --> Tools --> Terminal\n",
    "- Make sure the \"Shell path\" points to your preferred bash executable (e.g. /bin/zsh)\n",
    "- Apply and close Preferences\n",
    "<br><br>\n",
    "- Click the \"Terminal\" tab on the bottom\n",
    "- `which python3` to make sure PyCharm Terminal agrees with the system terminal configuration\n",
    "<br><br>\n",
    "- Top Menu --> VCS --> Git --> Remotes\n",
    "- Make sure a remote location with the name \"origin\" points to the URL of the nrnpy_tutorial on GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. git commands: pull, stash, add, commit, merge, push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `git pull origin master` - download any changes to the branch with the name \"master\" from the remote location named \"origin\" since you cloned the repository, or since the last time you \"pulled\"\n",
    "    - PyCharm will warn you if you have made local changes that would be over-written by the pull operation\n",
    "- `git stash` - if you want the remote changes to replace your local copy, you can \"stash\" the changes. On the next pull, your local changes will be over-written\n",
    "- `git add` - if you want a file that you created to be tracked by git, you can right-click on the filename and \"add\" it the list of tracked files\n",
    "- `git commit` - if you have made changes to one or more tracked files locally and you want to update the remote repository, you need to \"commit\" them to the record. This is just a local operation and does not yet change the upstream remote origin. You can add a message to describe the changes in this commit, and attribute yourself as the author of the changes.\n",
    "- `git pull` - if in your latest commits, you have made changes to the same lines of the same files as another collaborator, and you try to \"pull\" remote changes, PyCharm will detect the conflict and give you the opportunity to decide line-by-line which version you would like to use going forward. This is called a \"merge\" operation.\n",
    "- `git push` - Once you have merged, commit your changes again. Then you are ready to \"push\" those commits to the remote origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't worry, everything you do with git is (usually) reversible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Introduction to function optimization with scipy.optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a function that takes an array of free parameters, and produces a single float output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y1(x):\n",
    "    \"\"\"\n",
    "    The argument 'x' is an array of length 1.\n",
    "    \"\"\"\n",
    "    y = (x[0] - 4) ** 2. + 10.\n",
    "    return y\n",
    "\n",
    "test_x = np.arange(-10., 10., 0.1)\n",
    "test_y1 = [y1([xi]) for xi in test_x]\n",
    "plt.figure()\n",
    "plt.plot(test_x, test_y1)\n",
    "plt.xlabel('Input parameter x[0]')\n",
    "plt.ylabel('Output objective y1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a simple function, we could obtain the global minimum by graphing the function, or by solving the equation analytically. But when functions are complex, numerical optimization methods become useful tools to search for approximate local minimums.\n",
    "\n",
    "scipy.optimize.minimize is a general interface that can use many different algorithms to search for input parameters that minimize a provided function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "# initial guess for the input parameter\n",
    "x0 = 0.\n",
    "\n",
    "result = minimize(y1, [x0], options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that was easy. But how do we know what parameters it tested? We'll have to manually keep track by appending the values to a global variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_history = []\n",
    "y_history = []\n",
    "\n",
    "def y1(x):\n",
    "    \"\"\"\n",
    "    The argument 'x' is an array of length 1.\n",
    "    \"\"\"\n",
    "    x_history.append(x)\n",
    "    y = (x[0] - 4) ** 2. + 10.\n",
    "    y_history.append(y)\n",
    "    return y\n",
    "\n",
    "result = minimize(y1, [x0], options={'disp': True})\n",
    "\n",
    "plt.figure()\n",
    "for xi, yi in zip(x_history, y_history):\n",
    "    plt.scatter(xi[0], yi, marker='.', c='k')\n",
    "plt.scatter(result.x[0], result.fun, marker='o', c='r')\n",
    "plt.plot(test_x, test_y1)\n",
    "plt.xlabel('Input parameter x[0]')\n",
    "plt.ylabel('Output objective y1')\n",
    "plt.show()\n",
    "\n",
    "print(result.x, result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if there is no true global minimum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y2(x):\n",
    "    \"\"\"\n",
    "    The argument 'x' is an array of length 1.\n",
    "    \"\"\"\n",
    "    x_history.append(x)\n",
    "    y = np.exp(-x[0])\n",
    "    y_history.append(y)\n",
    "    return y\n",
    "\n",
    "test_y2 = [y2([xi]) for xi in test_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_history = []\n",
    "y_history = []\n",
    "result = minimize(y2, [x0], options={'disp': True})\n",
    "\n",
    "plt.figure()\n",
    "for xi, yi in zip(x_history, y_history):\n",
    "    plt.scatter(xi[0], [yi], marker='.', c='k')\n",
    "plt.scatter(result.x[0], result.fun, marker='o', c='r')\n",
    "plt.plot(test_x, test_y2)\n",
    "plt.xlabel('Input parameter x[0]')\n",
    "plt.ylabel('Output objective y2')\n",
    "plt.show()\n",
    "\n",
    "print(result.x, result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no true global minimum, minimize will find a local one up to some error tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_history = []\n",
    "y_history = []\n",
    "result = minimize(y2, [x0], options={'disp': True}, tol=0.1)\n",
    "\n",
    "plt.figure()\n",
    "for xi, yi in zip(x_history, y_history):\n",
    "    plt.scatter(xi[0], [yi], marker='.', c='k')\n",
    "plt.scatter(result.x[0], result.fun, marker='o', c='r')\n",
    "plt.plot(test_x, test_y2)\n",
    "plt.xlabel('Input parameter x[0]')\n",
    "plt.ylabel('Output objective y2')\n",
    "plt.show()\n",
    "\n",
    "print(result.x, result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_history = []\n",
    "y_history = []\n",
    "result = minimize(y2, [x0], options={'disp': True}, tol=1e-12)\n",
    "\n",
    "plt.figure()\n",
    "for xi, yi in zip(x_history, y_history):\n",
    "    plt.scatter(xi[0], [yi], marker='.', c='k')\n",
    "plt.scatter(result.x[0], result.fun, marker='o', c='r')\n",
    "plt.plot(test_x, test_y2)\n",
    "plt.xlabel('Input parameter x[0]')\n",
    "plt.ylabel('Output objective y2')\n",
    "plt.show()\n",
    "\n",
    "print(result.x, result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the function has multiple local minima?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y3(x):\n",
    "    \"\"\"\n",
    "    The argument 'x' is an array of length 1.\n",
    "    \"\"\"\n",
    "    x_history.append(x)\n",
    "    y = np.sin(x[0])\n",
    "    y_history.append(y)\n",
    "    return y\n",
    "\n",
    "test_y3 = [y3([xi]) for xi in test_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_history = []\n",
    "y_history = []\n",
    "result = minimize(y3, [x0], options={'disp': True})\n",
    "\n",
    "plt.figure()\n",
    "for xi, yi in zip(x_history, y_history):\n",
    "    plt.scatter(xi[0], [yi], marker='.', c='k')\n",
    "plt.scatter(result.x[0], result.fun, marker='o', c='r')\n",
    "plt.plot(test_x, test_y3)\n",
    "plt.xlabel('Input parameter x[0]')\n",
    "plt.ylabel('Output objective y3')\n",
    "plt.show()\n",
    "\n",
    "print(result.x, result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the function has multiple local minima, the search can be limited to a bounded range of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_history = []\n",
    "y_history = []\n",
    "result = minimize(y3, [x0], options={'disp': True}, method='L-BFGS-B', bounds=((-1., 10.),))\n",
    "\n",
    "plt.figure()\n",
    "for xi, yi in zip(x_history, y_history):\n",
    "    plt.scatter(xi[0], [yi], marker='.', c='k')\n",
    "plt.scatter(result.x[0], result.fun, marker='o', c='r')\n",
    "plt.plot(test_x, test_y3)\n",
    "plt.xlabel('Input parameter x[0]')\n",
    "plt.ylabel('Output objective y3')\n",
    "plt.show()\n",
    "\n",
    "print(result.x, result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So gradient-based approaches do not always find the desired local minimum! Let's try a non-gradient-based algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_history = []\n",
    "y_history = []\n",
    "result = minimize(y3, [x0], options={'disp': True}, method='Nelder-Mead', bounds=((-1., 10.),))\n",
    "\n",
    "plt.figure()\n",
    "for xi, yi in zip(x_history, y_history):\n",
    "    plt.scatter(xi[0], [yi], marker='.', c='k')\n",
    "plt.scatter(result.x[0], result.fun, marker='o', c='r')\n",
    "plt.plot(test_x, test_y3)\n",
    "plt.xlabel('Input parameter x[0]')\n",
    "plt.ylabel('Output objective y3')\n",
    "plt.show()\n",
    "\n",
    "print(result.x, result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this algorithm does not respect bounds. We can manually implement them by hard coding our function to be optimized to return a very large error value when parameters are out of bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y3(x):\n",
    "    \"\"\"\n",
    "    The argument 'x' is an array of length 1.\n",
    "    \"\"\"\n",
    "    for xi, bi in zip(x, bounds):\n",
    "        if not bi[0] <= xi <= bi[1]:\n",
    "            return 1e9\n",
    "    x_history.append(x)\n",
    "    y = np.sin(x[0])\n",
    "    y_history.append(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_history = []\n",
    "y_history = []\n",
    "bounds=((-1., 10.),)\n",
    "\n",
    "result = minimize(y3, [x0], options={'disp': True}, method='Nelder-Mead')\n",
    "\n",
    "plt.figure()\n",
    "for xi, yi in zip(x_history, y_history):\n",
    "    plt.scatter(xi[0], [yi], marker='.', c='k')\n",
    "plt.scatter(result.x[0], result.fun, marker='o', c='r')\n",
    "plt.plot(test_x, test_y3)\n",
    "plt.xlabel('Input parameter x[0]')\n",
    "plt.ylabel('Output objective y3')\n",
    "plt.ylim((-2., 2.))\n",
    "plt.show()\n",
    "\n",
    "print(result.x, result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm, also known as \"Simplex\", only wants to look locally. It's a good \"polisher\", but we need a better way to search the whole bounded range. \"Basinhopping\" or \"Simulated annealing\" is good for this:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.basinhopping.html#scipy.optimize.basinhopping\n",
    "\n",
    "In every iteration, this algorithm will generate new parameters by taking \"steps\" from a previously visited point in the parameter space. Then it will try to use a local minimizer to polish the result. The initial stepsize can be specified, and with every iteration, the \"temperature\" decreases, which reduces the stepsize and decreases the error tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import basinhopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_history = []\n",
    "y_history = []\n",
    "bounds=((-1., 10.),)\n",
    "\n",
    "stepsize = 0.5 * (bounds[0][1] - bounds[0][0])\n",
    "\n",
    "result = basinhopping(y3, [x0], minimizer_kwargs={'method': 'Nelder-Mead'}, stepsize=stepsize, disp=True)\n",
    "\n",
    "plt.figure()\n",
    "for xi, yi in zip(x_history, y_history):\n",
    "    plt.scatter(xi[0], [yi], marker='.', c='k')\n",
    "plt.scatter(result.x[0], result.fun, marker='o', c='r')\n",
    "plt.plot(test_x, test_y3)\n",
    "plt.xlabel('Input parameter x[0]')\n",
    "plt.ylabel('Output objective y3')\n",
    "plt.ylim((-2., 2.))\n",
    "plt.show()\n",
    "\n",
    "print(result.x, result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform bounded parameter optimization on the input resistance of a NEURON section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron import h\n",
    "h.load_file('stdrun.hoc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma = h.Section()\n",
    "soma.L = 20.\n",
    "soma.diam = 20.\n",
    "soma.insert('pas')\n",
    "\n",
    "soma_pas_g0 = soma(0.5).pas.g\n",
    "\n",
    "h.tstop = 400.\n",
    "v_init = -65.\n",
    "h.v_init = v_init\n",
    "soma(0.5).pas.e = v_init\n",
    "\n",
    "t = h.Vector()\n",
    "soma_voltage = h.Vector()\n",
    "t.record(h._ref_t, h.dt)  # record the time base\n",
    "soma_voltage.record(soma(0.5)._ref_v, h.dt)  # record the voltage across the membrane in a segment\n",
    "\n",
    "step_current_stim = h.IClamp(soma(0.5))\n",
    "step_current_stim.amp = -0.05  # amplitude in nanoAmps\n",
    "step_current_stim.dur = 200.  # duration in milliseconds\n",
    "step_current_stim.delay = 200.  # start time of current injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_R_inp(t, v, i_amp, baseline_window=(195., 200.),  measurement_window=(395., 400.)):\n",
    "    baseline_indexes = np.where((baseline_window[0] <= t) & (t < baseline_window[1]))\n",
    "    measurement_indexes = np.where((measurement_window[0] <= t) & (t < measurement_window[1]))\n",
    "    baseline_v = np.mean(v[baseline_indexes])\n",
    "    measurement_v = np.mean(v[measurement_indexes])\n",
    "    delta_v = abs(baseline_v - measurement_v)\n",
    "    R_inp = (delta_v / 1000.) / (abs(i_amp) / 1e9) / 1e6 # convert mV to V, nA to A, and Ohm to MegaOhm\n",
    "    return R_inp\n",
    "\n",
    "def get_soma_R_inp_error(x, target, bounds, sim_history):\n",
    "    for xi, bi in zip(x, bounds):\n",
    "        if not bi[0] <= xi <= bi[1]:\n",
    "            return 1e9\n",
    "    soma(0.5).pas.g = x[0]\n",
    "    h.run()\n",
    "    t_array = np.array(t)\n",
    "    v_array = np.array(soma_voltage)\n",
    "    i_amp = step_current_stim.amp\n",
    "    soma_R_inp = get_R_inp(t_array, v_array, i_amp)\n",
    "    error = (target - soma_R_inp) ** 2.\n",
    "    this_sim_summary = {}\n",
    "    this_sim_summary['t'] = t_array\n",
    "    this_sim_summary['soma_voltage'] = v_array\n",
    "    this_sim_summary['soma_R_inp'] = soma_R_inp\n",
    "    this_sim_summary['error'] = error\n",
    "    sim_history[tuple(x)] = this_sim_summary\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bounds = ((1e-12, 0.1),)\n",
    "stepsize = 0.5 * (bounds[0][1] - bounds[0][0])\n",
    "x0 = [soma_pas_g0]\n",
    "target_soma_R_inp = 150.\n",
    "\n",
    "sim_history = {} # {x0: {'t': array, 'soma_voltage': array, 'soma_R_inp': float, 'error': float}\n",
    "\n",
    "result = basinhopping(get_soma_R_inp_error, x0, stepsize=stepsize, disp=True, \n",
    "                     minimizer_kwargs={'method': 'Nelder-Mead', 'args': (target_soma_R_inp, bounds, sim_history)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(9., 5.))\n",
    "for xi, this_sim_summary in sim_history.items():\n",
    "    axes[0].scatter(xi[0], this_sim_summary['soma_R_inp'], marker='.', c='k')\n",
    "    axes[1].scatter(xi[0], this_sim_summary['error'], marker='.', c='k')\n",
    "axes[0].scatter(result.x[0], sim_history[tuple(result.x)]['soma_R_inp'], marker='o', c='r')\n",
    "axes[1].scatter(result.x[0], result.fun, marker='o', c='r')\n",
    "axes[0].set_xlabel('Somatic leak conductance (S/cm^2)')\n",
    "axes[1].set_xlabel('Somatic leak conductance (S/cm^2)')\n",
    "axes[0].set_ylabel('Somatic input resistance (MOhm)')\n",
    "axes[1].set_ylabel('Somatic input resistance objective error')\n",
    "fig.tight_layout(w_pad=3.)\n",
    "fig.show()\n",
    "\n",
    "optimal_pas_g = result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Introduction to NMODL, the language used to specify ion channel mechanisms in NEURON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the contents of the built-in NEURON mechanism defined in 'hh.mod':\n",
    "\n",
    "    TITLE hh.mod   squid sodium, potassium, and leak channels\n",
    "\n",
    "    COMMENT\n",
    "     This is the original Hodgkin-Huxley treatment for the set of sodium, \n",
    "      potassium, and leakage channels found in the squid giant axon membrane.\n",
    "      (\"A quantitative description of membrane current and its application \n",
    "      conduction and excitation in nerve\" J.Physiol. (Lond.) 117:500-544 (1952).)\n",
    "     Membrane voltage is in absolute mV and has been reversed in polarity\n",
    "      from the original HH convention and shifted to reflect a resting potential\n",
    "      of -65 mV.\n",
    "     Remember to set celsius=6.3 (or whatever) in your HOC file.\n",
    "     See squid.hoc for an example of a simulation using this model.\n",
    "     SW Jaslove  6 March, 1992\n",
    "    ENDCOMMENT\n",
    "\n",
    "    UNITS {\n",
    "            (mA) = (milliamp)\n",
    "            (mV) = (millivolt)\n",
    "        (S) = (siemens)\n",
    "    }\n",
    "\n",
    "    NEURON {\n",
    "            SUFFIX hh\n",
    "            USEION na READ ena WRITE ina\n",
    "            USEION k READ ek WRITE ik\n",
    "            NONSPECIFIC_CURRENT il\n",
    "            RANGE gnabar, gkbar, gl, el, gna, gk\n",
    "            GLOBAL minf, hinf, ninf, mtau, htau, ntau\n",
    "    }\n",
    "\n",
    "    PARAMETER {\n",
    "            gnabar = .12 (S/cm2)\t<0,1e9>\n",
    "            gkbar = .036 (S/cm2)\t<0,1e9>\n",
    "            gl = .0003 (S/cm2)\t<0,1e9>\n",
    "            el = -54.3 (mV)\n",
    "    }\n",
    "\n",
    "    STATE {\n",
    "            m h n\n",
    "    }\n",
    "\n",
    "    ASSIGNED {\n",
    "            v (mV)\n",
    "            celsius (degC)\n",
    "            ena (mV)\n",
    "            ek (mV)\n",
    "\n",
    "        gna (S/cm2)\n",
    "        gk (S/cm2)\n",
    "            ina (mA/cm2)\n",
    "            ik (mA/cm2)\n",
    "            il (mA/cm2)\n",
    "            minf hinf ninf\n",
    "        mtau (ms) htau (ms) ntau (ms)\n",
    "    }\n",
    "    \n",
    "    BREAKPOINT {\n",
    "            SOLVE states METHOD cnexp\n",
    "            gna = gnabar*m*m*m*h\n",
    "        ina = gna*(v - ena)\n",
    "            gk = gkbar*n*n*n*n\n",
    "        ik = gk*(v - ek)      \n",
    "            il = gl*(v - el)\n",
    "    }\n",
    "\n",
    "\n",
    "    INITIAL {\n",
    "        rates(v)\n",
    "        m = minf\n",
    "        h = hinf\n",
    "        n = ninf\n",
    "    }\n",
    "    \n",
    "    DERIVATIVE states {  \n",
    "            rates(v)\n",
    "            m' =  (minf-m)/mtau\n",
    "            h' = (hinf-h)/htau\n",
    "            n' = (ninf-n)/ntau\n",
    "    }\n",
    "\n",
    "    :LOCAL q10\n",
    "\n",
    "    \n",
    "    PROCEDURE rates(v(mV)) {  :Computes rate and other constants at current v.\n",
    "                          :Call once from HOC to initialize inf at resting v.\n",
    "            LOCAL  alpha, beta, sum, q10\n",
    "            TABLE minf, mtau, hinf, htau, ninf, ntau DEPEND celsius FROM -100 TO 100 WITH 200\n",
    "\n",
    "    UNITSOFF\n",
    "            q10 = 3^((celsius - 6.3)/10)\n",
    "                    :\"m\" sodium activation system\n",
    "            alpha = .1 * vtrap(-(v+40),10)\n",
    "            beta =  4 * exp(-(v+65)/18)\n",
    "            sum = alpha + beta\n",
    "        mtau = 1/(q10*sum)\n",
    "            minf = alpha/sum\n",
    "                    :\"h\" sodium inactivation system\n",
    "            alpha = .07 * exp(-(v+65)/20)\n",
    "            beta = 1 / (exp(-(v+35)/10) + 1)\n",
    "            sum = alpha + beta\n",
    "        htau = 1/(q10*sum)\n",
    "            hinf = alpha/sum\n",
    "                    :\"n\" potassium activation system\n",
    "            alpha = .01*vtrap(-(v+55),10) \n",
    "            beta = .125*exp(-(v+65)/80)\n",
    "        sum = alpha + beta\n",
    "            ntau = 1/(q10*sum)\n",
    "            ninf = alpha/sum\n",
    "    }\n",
    "\n",
    "    FUNCTION vtrap(x,y) {  :Traps for 0 in denominator of rate eqns.\n",
    "            if (fabs(x/y) < 1e-6) {\n",
    "                    vtrap = y*(1 - x/y/2)\n",
    "            }else{\n",
    "                    vtrap = x/(exp(x/y) - 1)\n",
    "            }\n",
    "    }\n",
    "\n",
    "    UNITSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mechanism specifies 3 distinct ion channels in one!\n",
    " - Passive leak conductance\n",
    " - Hodkin-Huxley-style sodium conductance with voltage-dependent activation gate and voltage-dependent inactivation gate\n",
    " - Hodkin-Huxley-style delayed rectifier potassium conductance with voltage-dependent activation gate\n",
    " \n",
    "## Exercise: Let's plot the voltage dependence of the \"m\", \"h\", and \"n\" gates:\n",
    " - Use the rates(v) function defined in the .mod file to create python functions that plot minf, hinf, and ninf as functions of v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10 = 1.  # For this purpose, temperature = 6.3 and the temperature sensitivity factor = 1.\n",
    "\n",
    "def vtrap(x, y):\n",
    "    if abs(x/y) < 1e-6:\n",
    "        return y * (1. - x / y / 2.)\n",
    "    else:\n",
    "        return x / (np.exp(x / y) - 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtau(v):\n",
    "    alpha = .1 * vtrap(-(v+40), 10)\n",
    "    beta =  4 * np.exp(-(v+65)/18)\n",
    "    this_sum = alpha + beta\n",
    "    return 1. / (q10 * this_sum)\n",
    "\n",
    "def minf(v):\n",
    "    alpha = .1 * vtrap(-(v+40), 10)\n",
    "    beta =  4 * np.exp(-(v+65)/18)\n",
    "    this_sum = alpha + beta\n",
    "    return alpha / this_sum\n",
    "\n",
    "def htau(v):\n",
    "    # fill in\n",
    "    return\n",
    "\n",
    "def hinf(v):\n",
    "    # fill in\n",
    "    return\n",
    "\n",
    "def ntau(v):\n",
    "    # fill in\n",
    "    return\n",
    "    \n",
    "def ninf(v):\n",
    "    # fill in\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.arange(-100., 100., 0.1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(v, minh(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a function expects a float, you can pass in a vector and get back a vector if you wrap it with np.vectorize()!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharex=True, figsize=(9., 5.))\n",
    "axes[0].plot(v, np.vectorize(mtau)(v))\n",
    "axes[0].set_xlabel('Voltage (mV)')\n",
    "axes[0].set_ylabel('Time constant (ms)')\n",
    "axes[0].set_title('Na activation gate time constant')\n",
    "axes[1].plot(v, np.vectorize(minf)(v))\n",
    "axes[1].set_xlabel('Voltage (mV)')\n",
    "axes[1].set_ylabel('Permeability factor')\n",
    "axes[1].set_title('Na activation gate state')\n",
    "fig.tight_layout(w_pad=3.)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharex=True, figsize=(9., 5.))\n",
    "axes[0].plot(v, np.vectorize(mtau)(v), label='Na activation')\n",
    "axes[0].plot(v, np.vectorize(htau)(v), label='Na inactivation')\n",
    "axes[0].set_xlabel('Voltage (mV)')\n",
    "axes[0].set_ylabel('Time constant (ms)')\n",
    "axes[0].set_title('Time constant')\n",
    "axes[1].plot(v, np.vectorize(minf)(v), label='Na activation')\n",
    "axes[1].plot(v, np.vectorize(hinf)(v), label='Na inactivation')\n",
    "axes[1].set_xlabel('Voltage (mV)')\n",
    "axes[1].set_ylabel('Permeability factor')\n",
    "axes[1].set_title('State')\n",
    "axes[0].legend(loc='best', frameon=False)\n",
    "fig.tight_layout(w_pad=3.)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Insert \"active\" voltage-dependent \"Hodgkin-Huxley\" ion channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma = h.Section()\n",
    "soma.L = 20.\n",
    "soma.diam = 20.\n",
    "soma.insert('hh')\n",
    "\n",
    "h.tstop = 600.\n",
    "v_init = -65.\n",
    "h.v_init = v_init\n",
    "\n",
    "t = h.Vector()\n",
    "soma_voltage = h.Vector()\n",
    "t.record(h._ref_t, h.dt)  # record the time base\n",
    "soma_voltage.record(soma(0.5)._ref_v, h.dt)  # record the voltage across the membrane in a segment\n",
    "\n",
    "step_current_stim = h.IClamp(soma(0.5))\n",
    "step_current_stim.amp = 0.1  # amplitude in nanoAmps\n",
    "step_current_stim.dur = 200.  # duration in milliseconds\n",
    "step_current_stim.delay = 200.  # start time of current injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.run()\n",
    "plt.figure()\n",
    "plt.plot(t, soma_voltage)\n",
    "plt.ylabel('Voltage (mV)')\n",
    "plt.xlabel('Time (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_mech = soma(0.5).hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_mech.   # tab to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordings can be established for the 3 ion channel conductances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = h.Vector()\n",
    "gl.record(soma(0.5).hh._ref_gl, h.dt)\n",
    "gna = h.Vector()\n",
    "gna.record(soma(0.5).hh._ref_gna, h.dt)\n",
    "gk = h.Vector()\n",
    "gk.record(soma(0.5).hh._ref_gk, h.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h.run()\n",
    "fig, axes = plt.subplots(2, sharex=True)\n",
    "axes[0].plot(t, gl, label='gl')\n",
    "axes[0].plot(t, gna, label='gna')\n",
    "axes[0].plot(t, gk, label='gk')\n",
    "axes[0].legend(loc='best', frameon=False)\n",
    "axes[1].plot(t, soma_voltage, label='soma vm')\n",
    "axes[1].legend(loc='best', frameon=False)\n",
    "axes[0].set_ylabel('Conductance (S/cm^2)')\n",
    "axes[1].set_ylabel('Voltage (mV)')\n",
    "axes[1].set_xlabel('Time (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkbar0 = soma(0.5).hh.gkbar\n",
    "gnabar0 = soma(0.5).hh.gnabar\n",
    "gl0 = soma(0.5).hh.gl\n",
    "T0 = h.celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times = h.Vector()\n",
    "spike_detector = h.NetCon(soma(0.5)._ref_v, None, sec=soma)\n",
    "spike_detector.delay = 0.  # ms\n",
    "spike_detector.threshold = -10.  # mV\n",
    "spike_detector.record(spike_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_current_stim.amp = 0.5\n",
    "test_amp_vals = [0.05 * i for i in range(6)]\n",
    "fig, axes = plt.subplots(len(test_amp_vals))\n",
    "for i, amp in enumerate(test_amp_vals):\n",
    "    step_current_stim.amp = amp\n",
    "    h.run()\n",
    "    print('Amp: %.2f;\\nspike times: %s' % (amp, str(np.array(spike_times))))\n",
    "    axes[i].plot(t, soma_voltage, label='Amp: %.2f;\\nspike count: %i' % (amp, len(spike_times)))\n",
    "    axes[i].legend(loc='best', frameon=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Challenge 1: Measure and plot an f-I curve\n",
    "\n",
    " - The relationship between input current (I) and output firing rate (f)\n",
    " - Make sure to only count spikes within the window of the step current injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Challenge 2: Simultaneously optimize both somatic input resistance and the slope of the f-I curve.\n",
    "\n",
    " - Hint: x0 = [gl0, gnabar0, gkbar0]\n",
    " - How to construct a single error value that reflects 2 objectives?\n",
    " - Target f-I slope should be ~10 Hz / 0.05 nA\n",
    " - f-I slope should really only be calculated from values of I that produced more than one spike. ___/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some papers to read for next week:\n",
    "\n",
    " - Stuart, Greg, and Nelson Spruston. \"Determinants of voltage attenuation in neocortical pyramidal neuron dendrites.\" Journal of Neuroscience 18.10 (1998): 3501-3510. https://www.jneurosci.org/content/18/10/3501.full\n",
    " - Hoffman, Dax A., et al. \"K+ channel regulation of signal propagation in dendrites of hippocampal pyramidal neurons.\" Nature 387.6636 (1997): 869-875. https://www.nature.com/articles/43119\n",
    " - Royeck, Michel, et al. \"Role of axonal NaV1. 6 sodium channels in action potential initiation of CA1 pyramidal neurons.\" Journal of neurophysiology 100.4 (2008): 2361-2380.\n",
    " https://journals.physiology.org/doi/full/10.1152/jn.90332.2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
